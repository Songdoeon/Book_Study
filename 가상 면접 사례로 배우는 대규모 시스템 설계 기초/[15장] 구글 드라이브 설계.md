## 🌈 Chapter 15 : 구글 드라이브 설계

<details><summary>정리</summary>
  
```
```

</details>

클라우드 저장소 서비스는 최근 높은 인기를 누리게 된 대표적 클라우드 서비스다.

Ex) 구글 드라이브, 드롭박스. 원드라이브, 아이클라우드 등 

##  📚 1단계 : 문제 이해 및 설계 범위 확정

이번 장에서는 다음의 설계에 집중할 것이다.

- 파일 추가
  - 가장 쉬운 방법은 파일을 구글 드라이브 안으로 떨어트리는 것이다.(drag - and - drop)
- 파일 다운로드
- 여러 단말의 파일 동기화
  - 한 단말에서 파일을 추가하면 다른 단말에도 자동으로 동기화되어야 한다.
- 파일 공유.
- 파일이 편집되거나 삭제되거나 새롭게 공유되었을 때 알림 표시

구글 문서 편집 및 협업 기능 등 여러 사용자가 같은 문서를 동시에 편집할 수 있도록 하는 서비스가 있지만 이 부분은 설계 범위에서 제외한다.

기능적 요구사항 이외에 다음 비-기능적 요구사항을 이해하는 것도 중요하다.

- 안정성
  - 데이터 소실은 발생하면 안 된다.
- 빠른 동기화 속도
  - 파일 동기화에 시간이 너무 많이 걸리면 사용자는 인내심을 잃고 해당 제품을 더 이상 사용하지 않게 될 것이다.
- 네트워크 대역폭
  - 이 제품이 네트워크 대역폭을 불필요하게 많이 소모하는것은 좋지않다.
  - 모바일 데이터 플랜을 사용하는 경우라면 더욱 별로다.
- 규모 확장성
  - 이 시스템은 아주 많은 양의 트래픽도 처리 가능해야 한다.
- 높은 가용성
  - 일부 서버에 장애가 발생하거나, 느려지거나, 네트워크 일부가 끊겨도 시스템은 계속 사용 가능해야 한다.

### 🎈 개략적 추정치
- 가입 사용자는 오천만(50 million)이고 천만 명의 DAU 사용자가 있다고 가정한다.
- 모든 사용자에게 10GB의 무료 저장공간 할당
- 매일 각 사용자가 평균 2개의 파일을 업로드 한다고 가정.
  - 각 파일의 평균 크기는 500KB
- 읽기:쓰기 비율은 1:1
- 필요한 저장공간 총량 = 5천만 사용자 x 10GB x= 500PB(페타바이트)
- 업로드 API QPS = 1천만 사용자 x 2회 업로드 / 24시간 / 3600 초 = 240
- 최대 QPS = QPS x 2 = 480


##  📚 2단계 : 개략적 설계안 제시 및 동의 구하기

이번에는 모든 것을 담은 한 대 서버에서 출발해 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 나가보도록 하겠다.

우선 아래 구성을 서버 한 대로 시작해보자

- 파일을 올리고 다운로드 하는 과정을 처리할 웹 서버
- 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 DB
- 파일을 저장할 저장소 시스템. 파일 저장을 위해 1TB의 공간을 사용할 것이다.

아파치 웹 서버, MySQL를 설치하고 업로드 되는 파일을 저장할 drive 라는 폴더를 준비한다.

drive폴더 안 namespace라 불리는 하위 폴더에 특정 사용자가 올린 파일이 보관된다.

각 파일과 폴더는 그 상대 경로를 네임스페이스 이름과 결합하면 유일하게 식별해 낼 수 있다.

```
- drive
  - user1
    - recipes
    - chicken_soup.txt
  - user2
    - football.move
    - sport.txt
  - user3
    - best_pic_ever.png
```

### 🎈 API
이 시스템은 기본적으로 세 가지 API가 필요하다.

파일 업로드 API, 다운로드 API 그리고 파일 갱신 히스토리 제공 API다.


#### 📕 파일 업로드 API
이 시스템은 두가지 종류의 업로드를 지원한다.

- 단순 업로드
  - 파일 크기가 작을 때 사용한다.
- 이어 올리기(resumable upload)
  - 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각되면 사용한다.
  - `https://api.example.com/files/upload?uploadType=resumable`
- 인자
  - uploadType = resumable
  - data : 업로드할 로컬 파일

이어 올리기는 다음 세 단계 절차로 이루어진다.

- 이어 올리기 URL을 받기 위한 최초의 요청 전송
- 데이터를 업로드하고 업로드 상태 모니터링
- 업로드에 장애가 발생하면 장애 발생시점부터 업로드를 재시작
  

#### 📕 파일 다운로드 API

`https://api.example.com/files/download`

```json
{
  "path": "/recipes/soup/best_soup.txt" // 다운로드 할 파일의 경로
}
```

#### 📕 파일 갱신 히스토리 API
`https://api.example.com/files/list_revisions`

```json
{
  "path": "/recipes/soup/best_soup.txt", // 갱신 히스토리를 가져올 파일의 경로
  "limit": 20 // 히스토리 길이의 최대치
}
```

지금까지 나열한 모든 API는 사용자 인증을 필요로 하고 HTTPS 프로토콜을 사용해야 한다.

SSL(Secure Socket Layer)를 지원하는 프로토콜을 이용하는 이유는 클라이언트와 백엔드 서버가 주고받는 데이터를 보호하기 위한 것이다.

### 🎈 단일 서버의 제약 극복

업로드 파일이 많아지다 보면 결국 파일 시스템은 가득 차게 된다.

데이터를 샤딩하여 어러 서버에 나누어 저장할 수 있지만 서버에 장애가 생기면 데이터의 유실 위험이 있을 것이다.

에어비앤비 같은 시장주도 기업들은 저장소로 AWS S3를 사용한다고 한다.

  > AWS S3 : Simple Storage Service의 약자로 S3는 업계 최고 수준의 규모 확장성, 가용성, 보안, 성능을 제공하는 객체 저장소 서비스다.

S3의 경우 다중화를 지원하는데, 같은 지역 안에서 다중화를 할 수도 있고 여러 지역에 걸쳐 다중화를 할 수도 있다.

이제 데이터 손실은 걱정없지만 개선할 부분이 더 남아있다.

- 로드밸런서
  - 트래픽을 분산과 특정 웹 서버에 장애가 발생시 자동으로 해당 서버를 우회해준다.
- 웹 서버
  - 웹 서버 추가로 트래픽 폭증에도 대응할 수 있어야 한다.
- 메타데이터 DB
  - DB를 파일 저장 서버에서 분리하여 SPOF를 회피한다.
  - 다중화 및 샤딩 정책을 적용하여 가용성과 규모 확장성 요구사항에 대응한다.
- 파일 저장소
  - S3를 사용하고 가용성, 데이터 무손실을 보장하기 위해 두개 이상의 지역에 데이터를 다중화한다.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/3000a3a0-78d4-457b-954b-3435aa4a71f8)

이 모든 부분을 개선하고 나면 웹 서버, 메타데이터 DB, 파일 저장소가 한 대 서버에서 여러 서버로 잘 분리 되었을 것이다.


### 🎈 동기화 충돌
두명 이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트 하려고 하는 경우 동기화 충돌이 발생할 수 있다.

우리는 먼저 처리되는 변경은 성공, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시할 것이다.

동기화 충돌 오류가 발생하면 해당 시점에 시스템에는 두 가지 버전의 파일이 존재한다.
- 사용자가 가지고 있는 로컬 사본
- 서버에 있는 최신 버전
  
이 상태에서 사용자는 두 파일을 하나로 합칠지 아니면 둘 중 하나를 다른 파일로 대체할지를 결정해야 한다.

### 🎈 개략적 설계안
지금부터 각각의 컴포넌트에 대해 상세히 알아보자.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/ccf9f1d0-6c31-4e8a-878c-8180b73cbe69)

- 사용자 단말
  - 사용자가 이용하는 웹브라우저나 모바일 앱 등의 클라이언트
- 블록 저장소 서버(block server)
  - 파일 블록을 클라우드 저장소에 업로드 하는 서버다.
  - 블록 저장소는 블록 수준 저장소(block-level storage)라고도 한다.
  - 클라우드 환경에서 데이터 파일을 저장하는 기술이다.
  - 파일을 여러개의 블록으로 나눠 저장하며, 각 블록에는 고유한 해시값이 할당된다.
  - 각 블록은 독립적인 객체로 취급되며, 클라우드 저장소에 보관된다.
  - 파일을 재구성하려면 블록들을 원래 순서대로 합쳐야 한다.
  - 우리는 드롭박스를 참고하여 한 블럭의 크기를 최대 4MB로 정했다.
- 클라우드 저장소
  - 파일을 블록 단위로 나눠 저장한다.
- 아카이빙 저장소(cold storage)
  - 오랫동안 사용되지 않은 비활서(inactive)데이터를 저장하기 위한  컴퓨터 시스템이다.
- 로드밸런서
  - 요청을 모든 API 서버에 고르게 분산한다.
- API 서버
  - 파일 업로드 외에 거의 모든 것을 담당하는 서버다.
  - 사용자 인증, 사용자 프로파일 관리, 파일 메타 데이터 갱신 등
- 메타데이터 DB
  - 사용자, 파일 블록, 버전 등의 정보를 관리한다.
  - 실제 파일은 클라우드에 보관하며, 이 DB는 오직 메타데이터만 관리한다.
- 메타데이터 캐시
  - 성능을 높이기 위해 자주 쓰이는 메타데이터는 캐시한다.
 - 알림 서비스
   - 특정 이벤트가 발생을 클라이언트에게 알리는데 쓰이는 발생/구독 프로토콜 기반 시스템이다.
   - 우리의 경우 클라이어트에게 파일 추가, 편집, 삭제를 알려 파일의 최신 상태를 확인핟록 하는 데 쓰인다.
- 오프라인 사용자 백업 큐
  - 클라이언트가 접속 중이 아니라 파일의 최신 상태를 확인할 수 없을 수도 있다.
  - 해당 정보를 이 큐에 두어 나중에 클라이언트가 접속했을 때 동기화될 수 있도록 한다.


##  📚 3단계 : 상세 설계
  
