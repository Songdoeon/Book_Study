## 🌈 Chapter 15 : 구글 드라이브 설계

<details><summary>정리</summary>
  
```
- 이번 장에서 우리는 구글 드라이브 시스템을 설계해 보았다.
- 높은 수준의 일관성 낮은 네트워크 지연, 그리고 빠른 동기화가 요구된다는 점이 설계 과정을 흥미진진하게 만들었다.
- 이번 장에서 만든 설계안은 크게 두 가지 부분으로 구성된다.
- 파일의 메타데이터를 관리하는 부분, 파일 동기화를 처리하는 부분이다.
- 알림 서비스는 이 두 부분과 병존하는 또 하나의 중요 컴포넌트다.
  - 롤 폴링을 사용하여 클라이언트로 하여금 파일의 상태를 최신으로 유지할 수 있도록 한다.
```

</details>

클라우드 저장소 서비스는 최근 높은 인기를 누리게 된 대표적 클라우드 서비스다.

Ex) 구글 드라이브, 드롭박스. 원드라이브, 아이클라우드 등 

##  📚 1단계 : 문제 이해 및 설계 범위 확정

이번 장에서는 다음의 설계에 집중할 것이다.

- 파일 추가
  - 가장 쉬운 방법은 파일을 구글 드라이브 안으로 떨어트리는 것이다.(drag - and - drop)
- 파일 다운로드
- 여러 단말의 파일 동기화
  - 한 단말에서 파일을 추가하면 다른 단말에도 자동으로 동기화되어야 한다.
- 파일 공유.
- 파일이 편집되거나 삭제되거나 새롭게 공유되었을 때 알림 표시

구글 문서 편집 및 협업 기능 등 여러 사용자가 같은 문서를 동시에 편집할 수 있도록 하는 서비스가 있지만 이 부분은 설계 범위에서 제외한다.

기능적 요구사항 이외에 다음 비-기능적 요구사항을 이해하는 것도 중요하다.

- 안정성
  - 데이터 소실은 발생하면 안 된다.
- 빠른 동기화 속도
  - 파일 동기화에 시간이 너무 많이 걸리면 사용자는 인내심을 잃고 해당 제품을 더 이상 사용하지 않게 될 것이다.
- 네트워크 대역폭
  - 이 제품이 네트워크 대역폭을 불필요하게 많이 소모하는것은 좋지않다.
  - 모바일 데이터 플랜을 사용하는 경우라면 더욱 별로다.
- 규모 확장성
  - 이 시스템은 아주 많은 양의 트래픽도 처리 가능해야 한다.
- 높은 가용성
  - 일부 서버에 장애가 발생하거나, 느려지거나, 네트워크 일부가 끊겨도 시스템은 계속 사용 가능해야 한다.

### 🎈 개략적 추정치
- 가입 사용자는 오천만(50 million)이고 천만 명의 DAU 사용자가 있다고 가정한다.
- 모든 사용자에게 10GB의 무료 저장공간 할당
- 매일 각 사용자가 평균 2개의 파일을 업로드 한다고 가정.
  - 각 파일의 평균 크기는 500KB
- 읽기:쓰기 비율은 1:1
- 필요한 저장공간 총량 = 5천만 사용자 x 10GB x= 500PB(페타바이트)
- 업로드 API QPS = 1천만 사용자 x 2회 업로드 / 24시간 / 3600 초 = 240
- 최대 QPS = QPS x 2 = 480


##  📚 2단계 : 개략적 설계안 제시 및 동의 구하기

이번에는 모든 것을 담은 한 대 서버에서 출발해 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 나가보도록 하겠다.

우선 아래 구성을 서버 한 대로 시작해보자

- 파일을 올리고 다운로드 하는 과정을 처리할 웹 서버
- 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 DB
- 파일을 저장할 저장소 시스템. 파일 저장을 위해 1TB의 공간을 사용할 것이다.

아파치 웹 서버, MySQL를 설치하고 업로드 되는 파일을 저장할 drive 라는 폴더를 준비한다.

drive폴더 안 namespace라 불리는 하위 폴더에 특정 사용자가 올린 파일이 보관된다.

각 파일과 폴더는 그 상대 경로를 네임스페이스 이름과 결합하면 유일하게 식별해 낼 수 있다.

```
- drive
  - user1
    - recipes
    - chicken_soup.txt
  - user2
    - football.move
    - sport.txt
  - user3
    - best_pic_ever.png
```

### 🎈 API
이 시스템은 기본적으로 세 가지 API가 필요하다.

파일 업로드 API, 다운로드 API 그리고 파일 갱신 히스토리 제공 API다.


#### 📕 파일 업로드 API
이 시스템은 두가지 종류의 업로드를 지원한다.

- 단순 업로드
  - 파일 크기가 작을 때 사용한다.
- 이어 올리기(resumable upload)
  - 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각되면 사용한다.
  - `https://api.example.com/files/upload?uploadType=resumable`
- 인자
  - uploadType = resumable
  - data : 업로드할 로컬 파일

이어 올리기는 다음 세 단계 절차로 이루어진다.

- 이어 올리기 URL을 받기 위한 최초의 요청 전송
- 데이터를 업로드하고 업로드 상태 모니터링
- 업로드에 장애가 발생하면 장애 발생시점부터 업로드를 재시작
  

#### 📕 파일 다운로드 API

`https://api.example.com/files/download`

```json
{
  "path": "/recipes/soup/best_soup.txt" // 다운로드 할 파일의 경로
}
```

#### 📕 파일 갱신 히스토리 API
`https://api.example.com/files/list_revisions`

```json
{
  "path": "/recipes/soup/best_soup.txt", // 갱신 히스토리를 가져올 파일의 경로
  "limit": 20 // 히스토리 길이의 최대치
}
```

지금까지 나열한 모든 API는 사용자 인증을 필요로 하고 HTTPS 프로토콜을 사용해야 한다.

SSL(Secure Socket Layer)를 지원하는 프로토콜을 이용하는 이유는 클라이언트와 백엔드 서버가 주고받는 데이터를 보호하기 위한 것이다.

### 🎈 단일 서버의 제약 극복

업로드 파일이 많아지다 보면 결국 파일 시스템은 가득 차게 된다.

데이터를 샤딩하여 어러 서버에 나누어 저장할 수 있지만 서버에 장애가 생기면 데이터의 유실 위험이 있을 것이다.

에어비앤비 같은 시장주도 기업들은 저장소로 AWS S3를 사용한다고 한다.

  > AWS S3 : Simple Storage Service의 약자로 S3는 업계 최고 수준의 규모 확장성, 가용성, 보안, 성능을 제공하는 객체 저장소 서비스다.

S3의 경우 다중화를 지원하는데, 같은 지역 안에서 다중화를 할 수도 있고 여러 지역에 걸쳐 다중화를 할 수도 있다.

이제 데이터 손실은 걱정없지만 개선할 부분이 더 남아있다.

- 로드밸런서
  - 트래픽을 분산과 특정 웹 서버에 장애가 발생시 자동으로 해당 서버를 우회해준다.
- 웹 서버
  - 웹 서버 추가로 트래픽 폭증에도 대응할 수 있어야 한다.
- 메타데이터 DB
  - DB를 파일 저장 서버에서 분리하여 SPOF를 회피한다.
  - 다중화 및 샤딩 정책을 적용하여 가용성과 규모 확장성 요구사항에 대응한다.
- 파일 저장소
  - S3를 사용하고 가용성, 데이터 무손실을 보장하기 위해 두개 이상의 지역에 데이터를 다중화한다.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/3000a3a0-78d4-457b-954b-3435aa4a71f8)

이 모든 부분을 개선하고 나면 웹 서버, 메타데이터 DB, 파일 저장소가 한 대 서버에서 여러 서버로 잘 분리 되었을 것이다.


### 🎈 동기화 충돌
두명 이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트 하려고 하는 경우 동기화 충돌이 발생할 수 있다.

우리는 먼저 처리되는 변경은 성공, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시할 것이다.

동기화 충돌 오류가 발생하면 해당 시점에 시스템에는 두 가지 버전의 파일이 존재한다.
- 사용자가 가지고 있는 로컬 사본
- 서버에 있는 최신 버전
  
이 상태에서 사용자는 두 파일을 하나로 합칠지 아니면 둘 중 하나를 다른 파일로 대체할지를 결정해야 한다.

### 🎈 개략적 설계안
지금부터 각각의 컴포넌트에 대해 상세히 알아보자.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/ccf9f1d0-6c31-4e8a-878c-8180b73cbe69)

- 사용자 단말
  - 사용자가 이용하는 웹브라우저나 모바일 앱 등의 클라이언트
- 블록 저장소 서버(block server)
  - 파일 블록을 클라우드 저장소에 업로드 하는 서버다.
  - 블록 저장소는 블록 수준 저장소(block-level storage)라고도 한다.
  - 클라우드 환경에서 데이터 파일을 저장하는 기술이다.
  - 파일을 여러개의 블록으로 나눠 저장하며, 각 블록에는 고유한 해시값이 할당된다.
  - 각 블록은 독립적인 객체로 취급되며, 클라우드 저장소에 보관된다.
  - 파일을 재구성하려면 블록들을 원래 순서대로 합쳐야 한다.
  - 우리는 드롭박스를 참고하여 한 블럭의 크기를 최대 4MB로 정했다.
- 클라우드 저장소
  - 파일을 블록 단위로 나눠 저장한다.
- 아카이빙 저장소(cold storage)
  - 오랫동안 사용되지 않은 비활서(inactive)데이터를 저장하기 위한  컴퓨터 시스템이다.
- 로드밸런서
  - 요청을 모든 API 서버에 고르게 분산한다.
- API 서버
  - 파일 업로드 외에 거의 모든 것을 담당하는 서버다.
  - 사용자 인증, 사용자 프로파일 관리, 파일 메타 데이터 갱신 등
- 메타데이터 DB
  - 사용자, 파일 블록, 버전 등의 정보를 관리한다.
  - 실제 파일은 클라우드에 보관하며, 이 DB는 오직 메타데이터만 관리한다.
- 메타데이터 캐시
  - 성능을 높이기 위해 자주 쓰이는 메타데이터는 캐시한다.
 - 알림 서비스
   - 특정 이벤트가 발생을 클라이언트에게 알리는데 쓰이는 발생/구독 프로토콜 기반 시스템이다.
   - 우리의 경우 클라이어트에게 파일 추가, 편집, 삭제를 알려 파일의 최신 상태를 확인핟록 하는 데 쓰인다.
- 오프라인 사용자 백업 큐
  - 클라이언트가 접속 중이 아니라 파일의 최신 상태를 확인할 수 없을 수도 있다.
  - 해당 정보를 이 큐에 두어 나중에 클라이언트가 접속했을 때 동기화될 수 있도록 한다.


##  📚 3단계 : 상세 설계

지금부터는 핵심 컴포넌트 상세 설계를 해볼것이다. 상세 설계할 컴포넌트는 다음과 같다.

- 블록 저장소 서버
- 메타데이터 DB
- 업로드 절차
- 다운로드 절차
- 알림 서비스
- 파일 저장소 공간
- 장애처리 흐름

### 🎈 블록 저장소 서버
정기적으로 갱신되는 큰 파일들은 업데이트가 일어날 때마다 전체 파일을 서버로 보내면 네트워크 대역폭을 많이 잡아먹게 된다.

최적화 방법은 다음 두 가지 정도를 생각해 볼 수 있다.

- 델타 동기화(delta sync)
  - 파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화하는 것이다.
- 압축(compression)
  - 블록 단위로 압축해 두면 데이터 크기를 많이 줄일 수 있다.
  - 압축 알고리즘은 파일 유형에 따라 정하다.
  - Ex) `.txt` → gzip, bzip2

- 이 시스템에서 블록 저장소 서버는 파일 업로드에 관계된 힘든 일을 처리하는 컴포넌트다.
- 클라이언트가 보낸 파일을 블록 단위로 나눠야 하고, 각 블록에 압축 알고리즘을 적용 및 암호화까지 해야한다.
- 아울러 전체 파일을 저장소 시스템으로 보내는 대신 수정된 블록만 전송해야 한다.

다음은 새 파일이 추가되었을 때 블록 저장소 서버가 동작하는 방법이다.

<img src = "https://github.com/Songdoeon/Book_Study/assets/96420547/c944a609-268d-49a7-b731-0b6f583153d7" width = 800 height = 400>

- 주어진 파일을 작은 블록들로 분할한다.
- 각 블록을 압축한다.
- 암호화 이후 클라우드 저장소로 보낸다.

블록 저장소 서버에 델타 동기화 전략과 압축 알고리즘을 도입으로 네트워크 대역폭 사용량을 절감했다.

### 🎈 높은 일관성 요구사항
우리는 강한 일관성(String Consistency)모델을 기본으로 지원해야 한다.

메타데이터 캐시와 DB 계층에서의 일관성을 유지하여 같은 파일이 다른 사용자에게 다르게 보여선 안된다.

메모리 캐시는 보통 결과적 일관성(eventual consistency)모델을 지원한다. 따라서 강한 일관성을 달성하려면 다음 사항을 보장해야 한다.

- 캐시에 보관된 사본과 데이터베이스에 있는 원본(master)이 일치한다.
- DB에 보관된 원본에 변경이 발생하면 캐시에 있는 사본을 무효화 한다.

관계형 데이터베이스는 ACID(Atomocity, Consistency, Isolation, Durability)를 보장하므로 강한 일관성을 보장하기 쉽다.

하지만 NoSQL은 이를 기본으로 지원하지 않으므로 동기화 로직 안에 프로그램해 넣어야한다.

우리는 관계형 데이터베이스를 채택하여 높은 일관성 요구사항에 대응한다.

### 🎈 메타데이터 DB

우리 DB 스키마의 설계안이다. 중요한 것만 간추린 단순형태이다.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/485f3339-899b-456b-a7ce-7a657244a4f6)

- user
  - 이름, 이메일, 프로파일 사진 등 사용자에 관계된 기본정보
- device
  - 단말 정보가 보관된다.
  - push_id는 모바일 푸시 알림을 보내고 받기 위한 것이다.
  - 한 사용자가 여러 대의 단말을 가질 수 있음을 유의하자.
- namespace
  - 사용자의 루트 디렉터리 정보가 보관된다.
- file
  - 파일의 최신 정보가 보관된다.
- file_version
  - 파일의 갱신이력이 보관된다.
  - 이 테이블은 읽기 전용으로 갱신 이력이 훼손되는 것을 막는다.
- block
  - 파일 블록에 대한 정보를 보관하는 테이블이다.
  - 특정 버전의 파일은 파일 블록을 올바른 순서로 조합하기만 하면 복원해 낼 수 있다.

  
### 🎈 업로드 절차
사용자가 파일을 업로드하면 무슨 일이 벌어지는지 자세히 살펴보자.

다음 그림은 두 개 요청이 병렬적으로 전송된 상황을 보여준다.

첫 번째 요청은 메타데이터를 추가하기 위한 것이고, 두 번째 요청은 파일을 클라우드 저장소로 업로드하기 위한 것이다.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/9b13a87b-f026-403a-88be-e362025de014)

- 파일 메타데이터 추가
  - 클라이언트1 이 새 파일의 메타데이터를 추가하기 위한 요청 전송
  - 새 파일의 메타데이터를 데이터베이스에 저장하고 업로드상태를 대기중으로 변경
  - 새 파일이 추가되었음을 알림 서비스에 통지
  - 알림 서비스는 관련된 클라이언트에게 파일이 업로드되고 있음을 알림
- 파일을 클라우드 저장소에 업로드
  - 클라이언트1 이 파일을 블록 저장소 서버에 업로드
  - 블록 저장소 서버는 파일을 블록 단위로 쪼갠 당므 압축하고 암호화 한다음 클라우드 저장소에 전송
  - 업로드가 끝나면 클라우드 스토리지느 완료 콜백을 호출, 이 콜백 호출은 API 서버로 전송
  - 메타데이터 DB에 기록된 해당 파일의상태를 완료로 변경
  - 알림 서비스에 파일 업로드가 끝났음을 통지
  - 알림 서비스는 관련 클라이언트에게 파일 업로드가 끝났음을 알림


### 🎈 다운로드 절차
파일 다운로드는 파일이 새로 추가되거나 편집되면 자동으로 시작된다.

클라이언트가 다른 클라이언트의 파일 변경을 감지하는 방법은 다음 두 가지 정도가 있다.

- 클라이언트 A가 접속중 다른 클라이어트가 파일을 변경한다면?
  
  → 알림 서비스가 클라이어트에게 변경이 발생했으니 새 버전을 끌어가야 한다고 알린다.
- 클라이언트 A가 네트워크 접속중이 아닐 경우?
  
  → 데이터는 캐시에 보관되며 해당 클라이언트가 접속한다면 그때 해당 클라이언트는 새 버전을 가져간다.

파일의 변경을 감지한 클라이언트는 우선 API 서버를 통해 메타데이터를 새로 받아야 하고 그 다음 블록들을 다운받아 파일을 재구성 해야 한다.

다음은 중요 컴포넌트의 흐름이다.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/91c80470-ecf4-48fe-99a1-ccd1bd2d79bb)

- 알림 서비스가 클라이언트2 에게 누군가 파일을 변경했음을 알림
- 알림을 확인하고 새로운 메타데이터를 요청
- API 서버는 메타데이터 DB에게 새 메타데이터 요청
- 새 메타 데이터를 순서대로 반환함
- 클라이언트 메타데이터를 이용하여 즉시 블록 다운로드 요청 전송
- 클라우드 저장소는 블록 서버에 요청된 블록 반환
- 클라이언트는 전송된 블록을 사용하여 파일 재구성


### 🎈 알림 서비스
파일의 일관성 유지를 위해 클라이언트는 로컬에서 파일 변경을 감지하는 순간 다른 클라이언트에게 그 사실을 알려 충돌 가능성을 줄여야 한다.

알림 서비스는 그 목적으로 사용된다.

알림 서비스는 이벤트 데이터를 클라이언트로 보낼 때 두 가지 정도의 선택지가 있다.

- 롱 폴링(long polling)
  - 드롭박스가 이 방식을 사용중이다.
- 웹 소켓(Web Socket)
  - 클라이언트와 서버 사이에 지속적인 통신 채널을 제공한다.
  - 양방향 통신이 가능하다.

둘다 좋은 방안이지만 우리는 롱 폴링을 사용할 것인데 이유는 다음과 같다.

- 채팅서비스와 달리 우리는 알림 서비스와 양방향 통신이 필요하지 않다.
  - 서버는 변경 사실을 클라이언트에게 알려주어야 하지만 반대 방향 통신은 필요없다.
- 웹소켓은 실시간 양방향 통신이 요구되는 채팅 같은 응용에 적합하다.
  - 구글 드라이브의 경우 알림을 보낼 일이 많이 없다.
  - 알림을 보내야 하는 경우에도 단시간에 많은 양의 데이터를 보낼 일은 없다.

롱 폴링 방안을 쓰면 다음과 같은 일들이 일어난다.

- 각 클라이언트는 알림 서버와 롱 폴링용 연결을 유지하다 변경을 감지하면 해당 연결을 끊는다.
- 이때 클라이언트는 반드시 메타데이터 서버와 연결해 파일의 최신 내역을 다운로드 해야한다.
- 해당 다운로드 작업이 끝났거나 연결 타임아웃 시간에 도달한 경우엔 즉시 새 요청을 보내어 롱 폴링 연결을 복원하고 유지해야 한다.

### 🎈 저장소 공간 절약
파일 갱신 이력을 보존하고 안정성을 보장하기 위해 파일의 여러 버전을 여러 데이터센터에 보관할 필요가 있다.

그런 상황에 모든 버전을 자주 백업하게 되면 저장용량이 너무 빨리 소진될 가능성이 있다.

이런 문제를 피하고 비용 절감에는 보통 다음 세 가지 방법을 사용한다.

- 중복제거(de-dupe)
  - 중복된 파일 블록을 계정 차원에서 제거하는 방법이 다.
  - 두 블록이 같은 블록인지는 해시 갓을 비교하여 판단한다.
- 지능적 백업 전략
  - 한도 설정
    - 보관해야 하는 파일 버전 개수에 상한을 둔다
    - 상한에 도달하면 제일 오래된 버전은 버린다.
  - 중요 버전만 보관
- 아카이빙 저장소
  - 몇달 혹은 수년간 이용되지 않는 데이터를 아카이빙 저장소에 옮긴다.
  - 아마존 S3 글래시어 같은 아카이빙 저장소 이용료는 S3보다 훨씬 저렴하다.

### 🎈 장애 처리
장애는 대규모 시스템이라면 피할 수 없으므로 설계 시 그점을 반드시 고려한다.

- 로드밸런서 장애
  - 로드밸런서에 장애가 발생할 경우 부 로드밸런서가 활성화되어 트래픽을 이어ㅏㄷ아야 한다.
  - 로드밸런서끼리는 보통 박동(heartbeat) 신호를 이용하여 모니터링 한다.
- 블록 저장소 서버 장애
  - 블록 저장소 서버에 장애가 발생하였다면 다른 서버가 미완료 상태 또는 대기 상태인 작업을 이어받아야 한다.
- 클라우드 저장소 장애
  - S3 버킷은 여러 지역 다중화가 가능하므로 단일 지역 장애 발생은 충분히 대처 가능하다.
- API 서버 장애
  - API 서버들은 무상태 서버다.
  - 로드밸런서로 장애가 발생한 서버를 격리하여 트래픽을 보내지 않는다.
- 메타데이터 캐시 장애
  - 메타데이터 캐시 서버도 다중화 한다.
- 메타데이터 DB 장애
  - 주 DB 장애
    - 부 DB중 하나를 주 DB로 바꾸고 부 DB서버를 새로 하나 추가한다.
  - 부 DB 장애
    - 다른 부 DB서버가 읽기 연산을 처리하도록 하고 그동안 장애 서버는 새 것으로 교체한다.
- 알림 서비스 장애
  - 접속중인 모든 사용자는 알림 서버와 롱 폴링 연결을 하나씩 유지하므로 알림 서비스는 많은 사용자와 연결을 유지하고 관리해야한다.
  - 2012년도의 드롭박스 발표에 따르면 한대의 알림 서비스 서버가 관리하는 연결 수는 백만 개가 넘는다.
  - 따라서 한 대 서버에 장애가 발생하면 백만 명 이상의 사용자가 롱 폴링을 다시 만들어야 한다.
  - 한 대 서버로는 유지하는 것은 가능하지만, 동시에 백만 개 접속을 시작하는 것은 불가능하다.
  - 따라서 복구는 상대적으로 많이 느릴 것이다.
- 오프라인 사용자 백업 큐 장애
  - 큐 다중화를 한다.
  - 구독중인 클라이언트들은 백업 큐로 구독 관계를 재설정 해야할 것이다.
 
##  📚 4단계 : 마무리

블록 저장소 서버를 거치지 않고 파일을 클라우드 저장소에 직업 업로드 한다면 업로드 시간이 빨라질 수 있다는 점이있지만 몇가지 단점도 있다.

- 분할, 압축, 암호화 로직을 클라이어트에 두어야 하므로 플랫폼별로 따로 구현해야 한다.(iOS, 안드로이드, 웹 등)
- 클라이언트가 해킹 당할 가능성이 있으므로 암호화 로직을 클라이언트 안에 두는 것은 적절치 않은 선택일 수 있다.

그리고 접속상태 관리로직을 별도 서비스로 옮기는 것도 생각해 볼 만하다.

관련 로직을 알림 서비스에서 분리해 내면 다른 서비스에도 쉽게 활용할 수 있게 되므로 좋을 것이다.
