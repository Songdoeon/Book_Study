## 🌈 Chapter 13 : 검색어 자동완성 시스템

<details><summary>정리</summary>
  
```
- 검색어 자동완성 시스템 주요 구성요소는 다음과 같다.
  - 데이터 수집 서비스
  - 질의 서비스(query service)
  - 트라이(trie) 자료구조
  - 규모 확장이 가능한 저장소
  - 트라이 연산
```

</details>

구글 검색 또는 아마존 웹 사이트 검색창에 단어를 입력하다 보면 입력중인 글자에 맞는 검색어가 자동으로 완성되어 표시되는 것을 볼 수 있다.

이런 기능은 보통 검색어 자동완성 이라부른다. 우리는 많이 이용된 검색어 k개를 자동완성하여 출력하는 시스템을 설계해 보도록 하겠다.

##  📚 1단계 : 문제 이해 및 설계 범위 확정

> 지원자: 사용자가 입력하는 단어는 자동완성될 검색어의 첫 부분이어야 하나요? 아니면 중간 부분이 될 수도 있습니까?
> 
> 면접관: 첫 부분으로 한정하겠습니다.
>
> 지원자: 몇 개의 자동완성 검색어가 표시되어야합니까?
> 
> 면접관: 5개입니다.
> 
> 지원자: 자동완성 검색어 5개를 고르는 기준은 무엇입니까?
> 
> 면접관: 질의 빈도에 따라 정해지는 검색어 인기 순위를 기준으로 삼겠습니다.
> 
> 지원자: 맞춤법 검사 기능도 제공해야 합니까?
> 
> 면접관: 아뇨 맞춤법 검사나 자동수정은 지원하지 않습니다.
> 
> 지원자: 질의는 영어입니까?
> 
> 면접관: 네. 하지만 시간이 허락한다면 다국어 지원을 생각해도 좋습니다.
> 
> 지원자: 대문자나 특수 문자 처리도 해야 합니까?
> 
> 면접관: 아뇨 모든 질의는 영어 소문자로 이루어진다고 가정하겠습니다.
> 
> 지원자: 얼마나 많은 사용자를 지원해야 합니까?
> 
> 면접관: 일간 능동 사용자(DAU) 기준으로 천만명 입니다.

### 🎈 요구사항

위의 요구사항을 정리해 보았다.

- 빠른 응답 속도
  - 사용자가 검색어를 입력함에 따라 자동완성 검색어도 충분히 빨리 표시되어야 한다.
  - 페이스북 검색어 자동완성 시스템에 관한 문서를 보면 시스템 응답속도는 100ms 이내여야 한다.
- 연관성
  - 자동완성되어 출력되는 검색어는 사용자가 입력한 단어와 연관된 것이어야 한다.
- 정렬
  - 시스템의 계산 결과는 인기도(popularity) 등의 순위 모델(ranking model)에 의해 정렬되어 있어야 한다.
- 규모 확장성
  - 시스템은 많은 트래픽을 감당할 수 있도록 확장 가능해야 한다.
- 고가용성
  - 시스템의 일부에 장애가 발생하거나, 느려지거나, 예상치 못한 네트워크 문제가 생겨도 시스템은 계속 사용 가능해야 한다.
 

### 🎈 개략적 규모 추정

- DAU는 천만 명으로 가정한다.
- 평균적으로 한 사용자는 매일 10건의 검색을 수행한다고 가정한다.
- 질의할 때마다 평균적으로 20바이트의 데이터를 입력한다고 가정한다
  - 문자 인코딩 방법으로는 ACSII를 사용한다고 가정한다(1문자 == 1바이트)
  - 질의문은 평균적으로 4개 단어로 이루어진다고 가정할 것이며, 각 단어는 평균 5글자로 구정된다.
  - 따라서 질의당 평균 4 x 5 = 20바이트 이다.
- 검색창에 글자를 입력할 때 마다 클라이언트는 검색어 자동완성 백엔드에 요청을 보낸다.
  - 따라서 평균 1회검색당 20건의 요청이 백엔드로 전달된다.(한글자 당 한번)
- 대략 초당 24,000건의 질의(QPS)가 발생할 것이다.
  - 10,000,000 사용자 x 10질의 x 20자 / 3600(초)
- 최대 QPS = QPS x 2 = 대략 48000건
- 질의 가운데 20% 정도는 신규 검색어라고 가정할 것이다.
  - 따라서 매일 대략 0.4GB 정도의 신규 데이터가 시스템에 추가된다.

##  📚 2단계 : 개략적 설계안 제시 및 동의 구하기

개략적으로 보면 시스템은 두 부분으로 나뉜다.

- 데이터 수집 서비스(data gathering service)
  - 사용자가 입력한 질의를 실시간으로 수집하는 시스템이다.
  - 데이터가 많은 애플리케이션에 실시간 시스템은 그다지 바람직 않지만 설계안을 만드는 출발점으로는 괜찮다.
  - 상세 설계안을 준비할 때 보다 현실적인 안으로 교체하도록 하겠다.
- 질의 서비스(query service)
  - 주어진 질의에 다섯 개의 인기 검색어를 정렬해 내놓는 서비스이다.

### 🎈 데이터 수집 서비스
질의문과 사용빈도를 저장하는 빈도 테이블(frequency table)이 있다고 가정하겠다.

사용자가 twitch, twitter, twitter, twillo를 순서대로 검색하면 다음과 같이 바뀌어 나가게 된다.
![image](https://github.com/Songdoeon/Book_Study/assets/96420547/f33f5354-2b8b-47f0-b839-53d9a00054bc)

### 🎈 질의 서비스

<img src = "https://github.com/Songdoeon/Book_Study/assets/96420547/60bef609-af00-4a2c-8244-70d7b9a2bcea" width = 240 height = 350>

- query
  - 질의문을 저장하는 필드
- frequency
  - 질의문이 사용된 빈도를 저장하는 필드

<img src = "https://github.com/Songdoeon/Book_Study/assets/96420547/fb83b0b4-0930-4401-9453-4ebc57957328" width = 400 height = 350>

사용자가 `tw`를 검색창에 입력하면 "top 5" 자동완성 검색어가 표시되어야 한다.



```sql
SELECT * FROM frequency_table
WHERE query LIKE `prefix%`
ORDER BY frequency DESC
LIMIT 5;
```
가장 많이 사용된 5개 검색어는 다음과 같이 계산할 수 있다.

데이터 양이 적을 때는 나쁘지 않은 설계안이지만, 데이터가 아주 많아지면 데이터베이스가 병목이 될 수 있다.


##  📚 3단계 : 상세 걸계

데이터 수집 서비스와 질의 서비스의 두 부분으로 구성된 개략적 설계안은 최적화된 결과물이라 말하기 어렵지만 출발점으로서는 썩 괜찮은 안이었다.

이번 절에서는 컴포넌트를 몇 개 골라 더 상세히 설계하고 다음 순서로 최적화 방안을 논의할 것이다.

- 트라이(trie) 자료구조
- 데이터 수집 서비스
- 질의 서비스
- 규모 확장이 가능한 저장소
- 트라이 연산

### 🎈 트라이 자료구조
개략적 설계안에서는 관계형 RDBMS를 저장소로 사용했었다.

하지만 RDBMS를 이용해 가장 인기있었던 다섯 개 질의문을 골라내는 방안은 효율적이지 않다.

이 문제는 트라이를 사용해 해결할 것이다. 트라이가 시스템의 핵심적 부분이 될 것이므로, 충분한 시간을 할애하여 주어진 요구사항에 딱 맞는 트라이를 만들도록 할 것이다.

> 트라이(trie) : 접투어 트리(prefix tree) 라고도 하며 문자열을 꺼내는 연산에 초점을 맞춘 자료구조다.

- 트라이는 트리 형태의 자료구조다.
- 이 트리의 루트 노드는 . 빈문자열을 나타낸다.
- 각 노드는 글자 하나를 저장하며, 26개의 자식 노드를 가질 수 있다.
- 각 트리 노드는 하나의 단어 또는 접두어 문자열을 나타낸다.

다음은 `tree`, `try`, `true`, `toy`, `wish`, `win` 이 보관된 트라이다.

기본 트라이 자료구조는 노드에 문자들을 저장한다. 이용빈도에 따라 정렬된 결과를 내놓기 위해 노드에 빈도 정보까지 저장할 필요가 있다. 

가령 아래와 같은 빈도 테이블이 있다고 가정하자.
![image](https://github.com/Songdoeon/Book_Study/assets/96420547/c502cc3a-6c75-4d1c-81cb-6eb781da4c52)

용어 몇가지를 정리하고 넘어가자.

- p : 접두어의 길이
- n : 트라이 안에 있는 노드의 개수
- c : 주어진 노드의 자식 노드 개수

가장 많이 사용된 질의어 k개는 다음과 같이 찾을 수 있다.

- 해당 접두어를 표현하는 노드를 찾는다.
  - 시간 복잡도는 O(p)다.
- 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다.
  - 유효한 검색 문자열을 구성하는 노드가 유효 노드다.
  - 시간 복잡도는 O(c)다.
- 유효 노드들을 정렬하여 가장 인기 있는 검색어 k개를 찾는다.
  - 시간 복잡도는 O(clogc)다.

다음은 `k = 2` 이며, 검색창에 `be`를 검색했을 경우이다.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/1e5a5068-9c87-4531-a0b2-6d1c28e6e1a7)

- 접두어 노드 be를 찾는다.
- 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다.
  - [beer:10], [best:35], [bet:29]
- 유효 노드를 정렬하여 2개만 골라낸다.
  - [best:35]와 [bet:29]가 접두어 tr에 대해 검색된 2개의 인기 검색어다.

이 알고리즘은 직관적이지만, 최악의 경우 k개 결과를 얻으려고 전체 트라이를 다 검색해야하는 일이 생길 수 있다.

이문제를 해결할 방법으로는 다음 두가지가 있다.

- 접두어 최대 길이를 제한
- 각 노드에 인기 검색어를 캐시

이 두가지 최적화 방안을 순서대로 살펴보자.

#### 📕 접두어 최대 길이 제한
사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없다.

따라서 p값은 작은 정수값이라고 가정해도 안전하다.

검색어 최대 길이를 제한할 수 있다면 접두어 노드를 찾는 단계의 시간 복잡도는 O(p)에서 O(1) 수준으로 바뀔 것이다.


#### 📕 노드에 인기 검색어 캐시

각 노드에 k개의 인기 검색어를 저장해 두면 전체 트라이를 검색하는 일을 방지할 수 있다.

- 각 노드에 이렇게 인기 질의어를 캐시하면 top 5 검색어를 질의하는 시간 복잡도를 엄청나게 낮출 수 있다.
- 하지만 각 노드에 질의어를 저장할 공간이 많이 필요하게 된다는 단점도 있다.
- 그러나 빠른 응답속도가 아주 중요할 때는 이 정도 저장공간을 희생할 만한 가치는 있다.

다음은 개선된 트라이 구조다. 각 노드에 인기 검색어를 저장하도록 했다.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/69e5fa8f-28a7-4af0-b383-e99bc4854b64)

앞의 두 가지 최적화 기법을 적용하면 시간 복잡도가 어떻게 달라지는지 알아 보면 다음과 같다.

- 접두어 노드를 찾는 시간 복잡도는 O(1)로 바뀐다.
- 최고 인기 검색어 5개를 찾는 지르이의 시간 복잡도도 O(1)로 바뀐다.
  - 검색 결과가 이미 캐시되어 있어서다.

각 단계의 시간 복잡도가 O(1)로 바뀐 덕분에, 최고 인기 검색어 k개를 찾는 전체 알고리즘의 복잡도도 O(1)로 바뀌게 된다.
(대신 한번 검색할때 마다 빈도수를 바꿔주고 top5 캐싱까지 계속 해야겠지?)

### 🎈 데이터 수집 서비스
본 설계안은 사용자가 검색창에 뭔가 타이핑 할 때마다 실시간으로 데이터를 수정했다.

이 방법은 다음 두가지 문제로 실용적이지 않다.

- 매일 수천만 건의 질의가 입력된다
  
  → 그때마다 트라이를 갱신하면 질의 서비스는 심각하게 느려질 것이다.
- 일단 트라이가 만들어지고 나면 인기 검색어는 그다지 자주 바뀌지 않을 것이다.

  →  그러니 트라이는 그렇게 자주 갱신할 필요가 없다.


규모 확장이 쉬운 데이터 수집 서비스를 만들려면 데이터가 어디서 오고 어떻게 이용되는지를 살펴야 한다.

- 트위터 같은 실시간 애플리케이션이라면?
  
  →  제안되는 검색어를 항상 신선하게 유지할 필요가 있을 수 있다.
- 구글 검색 같은 애플리케이션이라면 그렇게 자주 바꿔줄 이유는 없을 것이다.

사례가 달라지더라도 데이터 수집 서비스의 토대는 바뀌지 않을 것이다.

트라이를 만드는데 쓰는 데이터는 보통 데이터 분석 서비스나 로깅 서비스로부터 올 것 이기 때문이다.

다음은 데이터 분석 서비스의 수정된 설계안이다.

![image](https://github.com/Songdoeon/Book_Study/assets/96420547/2cc9484f-5aa5-4778-8e4b-9167cab263b5)

#### 📕 데이터 분석 서비스 로그
데이터 분석 서비스 로그에는 검색창에 입력된 질의에 관한 원본 데이터가 보관된다.

새로운 데이터가 추가될 뿐 수정은 이루어지지 않으며 로그 데이터에는 인덱스를 걸지 않는다.

<img src = "https://github.com/Songdoeon/Book_Study/assets/96420547/9c74ffa3-af9e-4e0b-9b85-3897991d143b" width = 400 height = 330>

#### 📕 로그 취합 서버
데이터 분석 서비스로부터 나오는 로그는 보통 그 양이 엄청나고 데이터 형식도 제각각인 경우가 많기에 잘 취합하여야 한다.

데이터 취합 방식은 서비스의 사례에 따라 달라지기에 데이터 취합의 실시간성이 얼마의 중요도를 가지는지 확인하자

- 트위터 같은 실시간 서비스의 경우 결과를 빨리 보여주는 것이 중요하므로 데이터 취합 주기를 짧게 가져간다.
- 대부분의 경우 일주일에 한 번 정도로 로그를 취합해도 충분할 것이다.

#### 📕 취합된 데이터

- `time` : 해당 주가 시작한 날짜
- `frequencty` : 해당 질의가 해당 주에 사용된 횟수의 합

<img src = "https://github.com/Songdoeon/Book_Study/assets/96420547/ba92c3c8-b6f5-4a8c-a373-4d0b17821983" width = 400 height = 330>

#### 📕 작업 서버
작업 서버(worker)는 주기적으로 비동기적 작업을 실행하는 서버 집합이다.

트라이 자료구조를 만들고 트라이 데이터베이스에 저장하는 역할을 담당한다.

#### 📕 트라이 캐시
트라이 캐시는 분산 캐시 시스템으로 트라이 뎅터를 메모리에 유지하여 읽기 연산 성능을 높이는 구실을 한다.

매주 트라이 DB의 스냅샷을 떠서 갱신한다.

#### 📕 트라이 DB
트라이 DB는 지속성 저장소다.

트라이 데이터베이스로 사용할 수 있는 선택지로는 다음 두가지가 있다.

- 문서 저장소(document store)
  - 새 트라이를 매주 만들 것이므로, 주기적으로 트라이를 직렬화 하여 데이터베이스에 저장할 수 있다.
  - MongoDB 같은 문서 저장소를 활용하면 이런 데이터를 편리하게 저장할 수 있다.
- 키-값 저장소
  - 트라이는 아래 로직을 적용하면 해시 테이블 형태로 변환 가능하다
  - 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
  - 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환

다음은 트라이를 해시테이블로 대응시키는 방법이다.
<img src = "https://github.com/Songdoeon/Book_Study/assets/96420547/f66523a3-93ed-4cf2-a366-7f4ee1f44e7f" width = 800 height = 500>


### 🎈 질의 서비스
개략적 설계안에서 살펴본 질의 서비스는 데이터베이스를 활용하여 최고 인기 검색어 다섯 개를 골라냈다.

해당 설계안은 비효율성을 개선안 설계안이다.

<img src = "https://github.com/Songdoeon/Book_Study/assets/96420547/8c308ea5-b260-4917-98bd-434e3e6fdf49" width = 500 height = 650>

- 검색 질의가 로드밸런서로 전송 된다.
- 로드밸런서는 해당 질의를 API 서버로 보낸다.
- API 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제안 응답을 구성한다.
- 데이터가 트라이 캐시에 없는 경우에는 데이터를 DB에서 가져와 캐시에 채운다.
  - 그래야 다음에 같은 접두어에 대한 질의가 오면 캐시에 보관된 데이터를 사용해 처리할 수 있다.
  - 캐시 미스는 캐시 서버의 메모리가 부족하거나 캐시 서버에 장애가 있어 발생할 수 있다.

질의 서비스는 굉장히 빨라야 한다. 이를 위한 최적화 방안은 다음과 같다.

- Ajax 요청(request)
  - 웹 애플리케이션의 경우 브라우저는 보통 Ajax 요청을 보내 자동완성된 검색어 목록을 가져온다.
  - 요청을 보내고 받기 위해 페이지를 새로고침 할 필요가 없다는 장점이 있다.
- 브라우저 캐싱(browser caching)
  - 대부분 애플리케이션의 경우 자동완성 검색어 제안 결과는 짧은 시간 안에 자주 바뀌지 않는다.
  - 따라서 제안된 검색어들을 브라우저 캐시에 넣어두면 후속 질의의 결과는 해당 캐시에서 바로 가져갈 수 있다.
  - 구글 검색 엔진이 이런 캐시 메커니즘을 사용한다.
- 데이터 샘플링(Data sampling)
  - 대규모 시스템의 경우, 모든 질의 결과를 로깅하도록 해 놓으면 CPU 자원과 저장공간을 많이 소진하게 된다.
  - 데이터 샘플링 기법은 그럴 때 유용하다.
  - 즉 N개 요청 가운데 1개만 로깅하도록 하는 것이다.


### 🎈 트라이 연산
트라이는 검색어 자동완성 시스템의 핵심 컴포넌트다. 관련 연산들의 동작을 살펴보자


#### 📕 트라이 생성
트라이 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 DB로부터 취합된 데이터를 이용한다.

#### 📕 트라이 갱신
트라이 갱신에는 두가지 방법이 있다.

- 매주 한번 갱신하는 방법
  - 새로운 트라이를 만든 다음에 기존 트라이를 대체한다.
- 트라이의 각 노드를 개별적으로 갱신하는 방법
  - 이 방법은 트라이가 작을 경우 고려해볼만하다.
  - 트라이 노드를 개신할 때는 그 모든 상위 노드도 갱신해야 하는데, 상위 노드에도 인기 검색어 질의 결과가 보관되기 때문이다.

#### 📕 검색어 삭제
혐오성이 짙거나, 폭력적이거나, 위험한 질의어를 자동완성 결과에서 제거해야 한다.

- 트라이 캐시 앞에 필터 계층을 두어 부적절한 질의어가 반환되지 않도록 한다.
- 필터 규칙에 따라 검색 결과를 자유롭게 변경할 수 있다는 장점이 있다.
- 데이터베이스에서 해당 검색어를 물리적으로 삭제하는 것은 다음번 업데이트 사이클에 비동기적으로 진행하면 된다.


### 🎈 저장소 규모 확장
자동완성된 검색어를 사용자에게 제공하는 시스템 설계를 마쳤다.

트라이의 크기가 한 서버에 넣기엔 너무 큰 경우에도 대응할 수 있도록 규모 확장성 문제를 해결해보자.

영어만 지원하면 되기 때문에 첫글자를 기준으로 샤딩하는 방법을 생각해 볼 수 있다.

- 검색어 보관을 위해 두 대 서버가 필요하다면 a 부터 m 까지 글자로 시작하는 검색어를 첫 번째 나머지를 두 번째 서버에 저장한다.
- 세 대 서버가 필요하다면 a 부터 i , j 부터 r 까지 그리고 나머지로 나눈다.

이 방법은 사용 가능 서버가 최대 26개로 제한된다. 이 이상으로 서버 대수를 늘리려면 계층적으로 샤딩을 해야한다.

<img src= "https://github.com/Songdoeon/Book_Study/assets/96420547/6872cb59-6233-48fe-abdb-f60412b1d978" width = 600 height = 400>

- a로 시작하는 검색어를 두대로 나눈다면 aa 부터 am 까지 그리고 나머지로 나눌 수 있다.
- 하지만 위 방법은 c 로 시작하는 단어가 x 로 시작하는 단어 보다 많다는 것을 감안하면 서버균등 배분이 불가능하다.
- 이 문제를 해결하기 위해선 과거 질의 데이터의 패턴을 분석하여 샤딩해야한다.
  - 검색어 대응 샤드 관리자는 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보를 관리한다.
  - Ex) s 로 시작하는 검색어의 양이 u ~ z로 시작하는 단어의 수와 비슷하다면 s 에 대한 샤드 하나와 나머지를 합친 단어를 위한 샤드 하나 이런식으로 나눈다.

## 📚 4단계 : 마무리
상세 걸계 이후 면접관은 이런 질문들을 던질지도 모른다.

- 다국어 지원이 가능하도록 시스템을 확장하려면 어떻게 해야 할까요?
  - 비 영어권 국가에서 사용하는 언어를 지원하려면 트라이에 유니코드 데이터를 저장해야 한다.
  - 유니코드는 "고금을 막론하고 세상에 존재하는 모든 문자 체계를 지원하는 표준 인코딩 시스템" 이다.
- 국가별로 인기 검색어 순위가 다르다면 어떻게 할까요?
  - 국가별로 다른 트라이를 사용하도록 하면 된다.
  - 트라이를 CDN에 저장하여 응답속도를 높이는 방법도 생각해볼 수 있다.
- 실시간으로 변하는 검색어의 추이를 반영하려면 어떻게 해야 하나요?
  - 새로운 뉴스 이벤트가 생긴다든가 하는 이유로 특정 검색어의 인기가 갑자기 높아질 수 있다.
  - 현 설계안은 다음과 같은 이유로 그런 검색어를 지원하기에 적합하지 않다.
    - 작업 서버가 매주 한 번씩만 돌도록 되어 있어 적절하게 트라이를 갱신할 수 없다.
    - 설사 때 맞춰 실행된다 해도, 트라이 구성에 너무 많은 시간이 소요된다.
      
실시간 검색어 자동완성 시스템을 구축하는 것은 복잡한 문제로 이 책에서 다룰수 있는 범위를 넘어선다.

하지만 다음과 같은 아이디어들이 있다.

- 샤딩을 통하여 작업 대상 데이터의 양을 줄인다.
- 순위 모델을 바꾸어 최근 검색어에 보다 높은 가중치를 주도록 한다.
- 데이터가 스트림 형태로 올 수 있다
  - 한번에 모든 데이터를 동시에 사용할 수 없을 가능성이 있다는 점
  - 데이터가 스트리밍 된다는 것은 데이터가 지속적으로 생성된다는 뜻이다.
  - 스트림 프로세상에는 특별한 종류의 시스템이 필요하다
  - 아파치 하둡 맵리듀스, 아파치 스톰, 아파치 카프카 등이 그런 부류의 시스템이다.
  - 이에 대해 논의하려면 특정 도메인 지식이 필요하다.



